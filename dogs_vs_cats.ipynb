{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Kernels Redux Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am using VGG16 model which has won the imagenet competition a few years back. The utils files are just utility fucntions written for our benefit and has been taken as it is from fast.ai course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"data/cats-dogs-redux/sample/\"           #path to sample data\n",
    "#path = \"data/cats-dogs-redux/\"                  #path to entire data\n",
    "test_path = \"data/cats-dogs-redux/test/\"         #path to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda0: Tesla K80 (EE11:00:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload      #py3\n",
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch size can start from 2, then 4, then 8..so on untill 64 (afterwards its not advisable)\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Vgg class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1125 images belonging to 2 classes.\n",
      "Found 125 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "1125/1125 [==============================] - 29s - loss: 0.4776 - acc: 0.8524 - val_loss: 0.0077 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "# Grab a few images at a time for training and validation.\n",
    "# NB: They must be in subdirectories named based on their category\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training model on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "22500/22500 [==============================] - 545s - loss: 0.1262 - acc: 0.9684 - val_loss: 0.0675 - val_acc: 0.9832\n",
      "Epoch 2/3\n",
      "22500/22500 [==============================] - 543s - loss: 0.0969 - acc: 0.9772 - val_loss: 0.0608 - val_acc: 0.9848\n",
      "Epoch 3/3\n",
      "22500/22500 [==============================] - 546s - loss: 0.0918 - acc: 0.9787 - val_loss: 0.0708 - val_acc: 0.9844\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_batches(size = 64):\n",
    "    batches = vgg.get_batches(test_path, batch_size=size, shuffle=False)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_filename(batches, i):\n",
    "    return batches.filenames[i][8:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_rec(batches):\n",
    "    i = 0\n",
    "    records = []\n",
    "    for batch in batches:\n",
    "        imgs, labels = batch\n",
    "        probs, class_ids, class_names = vgg.predict(imgs, True)\n",
    "        for prob, class_id in zip(probs, class_ids):\n",
    "            if i >= len(batches.filenames):\n",
    "                return records\n",
    "            prob_dog = prob\n",
    "            if class_id == 0:\n",
    "                prob_dog = 1 - prob\n",
    "            filename = get_test_filename(batches, i)\n",
    "            records.append({'id' : filename ,  'label' : format(prob_dog, '.8f') })    \n",
    "            i = i + 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "        if i >= len(batches.filenames):\n",
    "            break\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_csv(records):\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df['id'] = pd.to_numeric(df['id'])\n",
    "    df = df.sort_values('id')\n",
    "    df.to_csv('new_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "testbatches = get_test_batches()\n",
    "records = get_test_rec(testbatches)\n",
    "write_submission_csv(records=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/new_submission.csv' target='_blank'>data/new_submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/cats-vs-dogs-redux-edition/data/new_submission.csv"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/\"\n",
    "from IPython.display import FileLink\n",
    "FileLink(path + 'new_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
